{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HZNDEakUpq5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvAm0pqwzI93",
        "outputId": "ccf2fec1-9238-40bc-be32-61e0be3d724c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_graph(G, color):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                     node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_embedding(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    h = h.detach().cpu().numpy()\n",
        "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    if epoch is not None and loss is not None:\n",
        "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch_geometric.nn import BatchNorm, PNAConv, global_add_pool\n",
        "from torch_geometric.utils import degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYkvvnzlUqkM",
        "outputId": "b551f6f0-7d49-4578-90d8-bf98cce295be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://data.pyg.org/datasets/qm9_v3.zip\n",
            "Extracting data/raw/qm9_v3.zip\n",
            "Processing...\n",
            "Using a pre-processed version of the dataset. Please install 'rdkit' to alternatively process the raw data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: QM9(130831):\n",
            "======================\n",
            "Number of graphs: 130831\n",
            "Number of features: 11\n",
            "Number of classes: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.datasets import TUDataset\n",
        "#dataset = TUDataset('data/ZINC', name='ZINC')\n",
        "\n",
        "dataset = QM9(root = './data')\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('======================')\n",
        "print(f'Number of graphs: {len(dataset)}')\n",
        "print(f'Number of features: {dataset.num_features}')\n",
        "print(f'Number of classes: {dataset.num_classes}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uv5kZgXiYCnV"
      },
      "outputs": [],
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Embedding, Linear, ModuleList, ReLU, Sequential\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from torch_geometric.datasets import ZINC\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import BatchNorm, PNAConv, global_add_pool\n",
        "from torch_geometric.utils import degree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp7bNF6-RTDY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Compute the maximum in-degree in the training data.\n",
        "max_degree = -1\n",
        "for data in dataset:\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "# Compute the in-degree histogram tensor\n",
        "deg = torch.zeros(max_degree + 1, dtype=torch.long)\n",
        "for data in dataset:\n",
        "    d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "    deg += torch.bincount(d, minlength=deg.numel())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly_SFLO3dDIw",
        "outputId": "b48f642c-05d3-443b-fc07-6469bc01d40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import PNAConv\n",
        "# Initialize the autoencoder model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GraphAutoencoder(nn.Module):\n",
        "   def __init__(self):\n",
        "        super(GraphAutoencoder, self).__init__()\n",
        "        num_features = 1\n",
        "        dim = 2\n",
        "\n",
        "\n",
        "        aggregators = ['mean', 'min', 'max', 'std']\n",
        "        scalers = ['identity', 'amplification', 'attenuation']\n",
        "\n",
        "\n",
        "        self.conv1 = PNAConv(in_channels=num_features, out_channels=4,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(4)\n",
        "\n",
        "\n",
        "        self.conv2 = PNAConv(in_channels=4, out_channels=8,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(8)\n",
        "\n",
        "\n",
        "        self.conv3 = PNAConv(in_channels=8, out_channels=4,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(4)\n",
        "\n",
        "\n",
        "        self.conv4 = PNAConv(in_channels=4, out_channels=2,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.bn4 = torch.nn.BatchNorm1d(2)\n",
        "\n",
        "        self.dconv1 = PNAConv(in_channels=2, out_channels=4,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.dbn1 = torch.nn.BatchNorm1d(4)\n",
        "\n",
        "\n",
        "        self.dconv2 = PNAConv(in_channels=4, out_channels=8,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.dbn2 = torch.nn.BatchNorm1d(8)\n",
        "\n",
        "\n",
        "        self.dconv3 = PNAConv(in_channels=8, out_channels=4,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.dbn3 = torch.nn.BatchNorm1d(4)\n",
        "\n",
        "\n",
        "        self.dconv4 = PNAConv(in_channels=4, out_channels=num_features,\n",
        "                           aggregators=aggregators, scalers=scalers, deg=deg)\n",
        "        self.dbn4 = torch.nn.BatchNorm1d(num_features)\n",
        "\n",
        "   def encode(self,x,edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(self.conv4(x, edge_index))\n",
        "        x = self.bn4(x)\n",
        "        return x\n",
        "\n",
        "   def decode(self, z, edge_index): # only pos and neg edges\n",
        "        z = F.relu(self.dconv1(z, edge_index))\n",
        "        z = self.dbn1(z)\n",
        "        z = F.relu(self.dconv2(z, edge_index))\n",
        "        z = self.dbn2(z)\n",
        "        z = F.relu(self.dconv3(z, edge_index))\n",
        "        z = self.dbn3(z)\n",
        "        z = F.relu(self.dconv4(z, edge_index))\n",
        "        z = self.dbn4(z)\n",
        "        return z\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a custom graph dataset with 5 graphs, each having 10 nodes and 8 features\n",
        "#dataset = CustomGraphDataset(num_graphs=5, num_nodes=10, num_features=8)\n",
        "#num_features = dataset.num_features\n",
        "\n",
        "epochs = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = \"cpu\"\n",
        "\n",
        "model= GraphAutoencoder()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = criterion = nn.MSELoss()\n",
        "\n",
        "batch_size = 1\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJeJV3W6XOt0"
      },
      "outputs": [],
      "source": [
        "from sys import path\n",
        "import pickle\n",
        "\n",
        "path=  '/content/modelv28.pkl'\n",
        "with open(path, 'rb') as file:\n",
        "      loaded_object = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89FUfK_KaDp7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return torch.linspace(beta_start, beta_end, timesteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLb5QesgaNIh"
      },
      "outputs": [],
      "source": [
        "timesteps = 300\n",
        "\n",
        "# define beta schedule\n",
        "betas = linear_beta_schedule(timesteps=timesteps)\n",
        "\n",
        "\n",
        "# define alphas\n",
        "alphas = 1. - betas\n",
        "\n",
        "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "\n",
        "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
        "\n",
        "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    batch_size = t.shape[0]\n",
        "    out = a.gather(-1, t.cpu())\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLaTKRrakNie"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLahSj5GesmP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_QhL2jaec65"
      },
      "outputs": [],
      "source": [
        "# forward diffusion\n",
        "def q_sample(x_start, t, noise=None):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x_start)\n",
        "\n",
        "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x_start.shape\n",
        "    )\n",
        "\n",
        "    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise, noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLpKyVR2j653"
      },
      "outputs": [],
      "source": [
        "def get_noisy_image(x_start, t):\n",
        "  # add noise\n",
        "  x_noisy,tar_noise = q_sample(x_start, t=t)\n",
        "\n",
        "\n",
        "  # turn back into PIL image\n",
        "\n",
        "\n",
        "  return x_noisy,tar_noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TZFImOiHm3b"
      },
      "source": [
        "import this for tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg818iu4bcNR"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import operator\n",
        "from itertools import chain, product\n",
        "from functools import partial\n",
        "from pathlib import Path\n",
        "from typing import Any, Optional, Callable, Tuple, Dict, Sequence, NamedTuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor, LongTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O97FPvAMbiRn"
      },
      "outputs": [],
      "source": [
        "import torch_geometric\n",
        "from torch_geometric.transforms import BaseTransform, Compose\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Dataset\n",
        "from torch_geometric.nn.aggr import SumAggregation\n",
        "import torch_geometric.nn as geom_nn\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_scatter import scatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssw4NcmjNgvB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo4WLqiV7-Uv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7628fb3"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def p_sample(model, data, t, t_index):\n",
        "    t1 = t_index\n",
        "    h_time = torch.empty_like(data.x[:, 0:1]).fill_(t1)\n",
        "    # Concatenate h and h_time along dimension 1\n",
        "    original_tensor = torch.cat([data.x, h_time], dim=1)\n",
        "\n",
        "\n",
        "# Reshape to the shape of torch.randn(1, 4, 11)\n",
        "    reshaped_tensor = original_tensor.view(1, data.num_nodes, 6)  # or use reshape\n",
        "\n",
        "    original_pos = data.pos\n",
        "    reshaped_pos = original_pos.view(1, data.num_nodes, 3)\n",
        "    #reshaped_pos=torch.randn(1, data.num_nodes, 3)\n",
        "    z,d= diff_model1(reshaped_tensor, reshaped_pos)\n",
        "\n",
        "    new_z = z[:, :, :5]\n",
        "    new_z = new_z.squeeze(0)\n",
        "\n",
        "\n",
        "    betas_t = extract(betas, t, data.x.shape)\n",
        "\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t, data.x.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, data.x.shape)\n",
        "\n",
        "\n",
        "    # Equation 11 in the paper\n",
        "    # Use our model (noise predictor) to predict the mean\n",
        "\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        data.x - betas_t * new_z / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "\n",
        "    if t_index == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        posterior_variance_t = extract(posterior_variance, t, data.x.shape)\n",
        "        noise = torch.randn_like(data.x)\n",
        "        # Algorithm 2 line 4:\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
        "\n",
        "# Algorithm 2 but save all images:\n",
        "@torch.no_grad()\n",
        "def p_sample_loop(model,data):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    b = 1\n",
        "    # start from pure noise (for each example in the batch)\n",
        "    data2.x = torch.cat([data2.x, data2.pos], dim=1)\n",
        "    t_init= torch.tensor([299])\n",
        "    imgs = []\n",
        "    features,tar= get_noisy_image(data.x, t_init)\n",
        "    data.x= features\n",
        "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
        "\n",
        "\n",
        "        data.x = p_sample(model, data, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
        "        imgs.append(data.x.cpu().numpy())\n",
        "        data.pos=data.x[:, -3:]\n",
        "    return imgs\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, data):\n",
        "    return p_sample_loop(model, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzogEGqK_a2q"
      },
      "outputs": [],
      "source": [
        "#come here\n",
        "@torch.no_grad()\n",
        "def p_sample(model, data, t, t_index):\n",
        "    t1 = t_index\n",
        "    h_time = torch.empty_like(data.x[:, 0:1]).fill_(t1)\n",
        "    # Concatenate h and h_time along dimension 1\n",
        "    original_tensor = torch.cat([data.x, h_time], dim=1)\n",
        "\n",
        "\n",
        "# Reshape to the shape of torch.randn(1, 4, 11)\n",
        "    reshaped_tensor = original_tensor.view(1, data.num_nodes, 3)  # or use reshape\n",
        "\n",
        "\n",
        "    original_pos = data.pos\n",
        "    reshaped_pos = original_pos.view(1, data.num_nodes, 3)\n",
        "    #reshaped_pos=torch.randn(1, data.num_nodes, 3)\n",
        "    z,d= diff_model1(reshaped_tensor, reshaped_pos)\n",
        "\n",
        "    new_z = z[:, :, :2]\n",
        "    new_z = new_z.squeeze(0)\n",
        "\n",
        "\n",
        "    betas_t = extract(betas, t, data.x.shape)\n",
        "\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t, data.x.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, data.x.shape)\n",
        "\n",
        "\n",
        "    # Equation 11 in the paper\n",
        "    # Use our model (noise predictor) to predict the mean\n",
        "\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        data.x - betas_t * new_z / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "\n",
        "    if t_index == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        posterior_variance_t = extract(posterior_variance, t, data.x.shape)\n",
        "        noise = torch.randn_like(data.x)\n",
        "        # Algorithm 2 line 4:\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
        "\n",
        "# Algorithm 2 but save all images:\n",
        "@torch.no_grad()\n",
        "def p_sample_loop(model,data):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    b = 1\n",
        "    # start from pure noise (for each example in the batch)\n",
        "    #data2.x = torch.cat([data2.x, data2.pos], dim=1)\n",
        "    t_init= torch.tensor([299])\n",
        "    imgs = []\n",
        "    features,tar= get_noisy_image(data.x, t_init)\n",
        "    data.x= features\n",
        "    #data.pos= features\n",
        "\n",
        "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
        "\n",
        "\n",
        "        data.x = p_sample(model, data, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
        "        #data.pos= data.x\n",
        "        imgs.append(data.x.cpu().numpy())\n",
        "        #data.pos=data.x[:, -3:]\n",
        "    return imgs\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, data):\n",
        "    return p_sample_loop(model, data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pqTe3N4I1mfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VROS4-0i8o1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gjM6zf2BLOR"
      },
      "outputs": [],
      "source": [
        "from sys import path\n",
        "import pickle\n",
        "\n",
        "path=  '/content/modelcoord.pkl'\n",
        "with open(path, 'rb') as file:\n",
        "      coord_model = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaRQkZb4L8rM"
      },
      "outputs": [],
      "source": [
        "from sys import path\n",
        "import pickle\n",
        "\n",
        "path=  '/content/modelv241.pkl'\n",
        "with open(path, 'rb') as file:\n",
        "      diff_model1 = pickle.load(file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}